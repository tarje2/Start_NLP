{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 감정 분석기 - 네이버 영화 리뷰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 로드\n",
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_table('./ratings_train.txt')\n",
    "test_data = pd.read_table('./ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data 처리\n",
    "## Train Data 처리\n",
    "\n",
    "# 1. 중복 확인/제거\n",
    "train_data['document'].nunique(), train_data['label'].nunique()\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "\n",
    "# 2. Null값 처리\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "\n",
    "# 3. 전처리(한글과 공백 제외 문자 제거)\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# 4. 전처리 후 Null값 처리\n",
    "train_data = train_data.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data 처리\n",
    "## Test Data 에도 동일한 작업 수행\n",
    "\n",
    "# 1.중복 확인/제거\n",
    "test_data['document'].nunique(), train_data['label'].nunique()\n",
    "test_data.drop_duplicates(subset = ['document'], inplace=True)\n",
    "\n",
    "# 2. Null값 처리\n",
    "\n",
    "# 3. 전처리(한글과 공백 제외 문자 제거)\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "\n",
    "# 4. 전처리 후 Null값 처리\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 중복, null값, 전처리(한글, 공백 제외), 전처리 후 null값 처리까지 한 데이터 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 토큰화 및 불용어(Stopwords) 제거\n",
    "\n",
    "# 한국어 불용어\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "#한국어 불용어 리스트 100개(https://bab2min.tistory.com/544#google_vignette)\n",
    "#stopwords = ['이','있','하','것','들','그','되','수','이','보','않','없','나','사람','주','아니','등','같','우리','때','년','가','한','지','대하','오','말','일','그렇','위하','때문','그것','두','말하','알','그러나','받','못하','일','그런','또','문제','더','사회','많','그리고','좋','크','따르','중','나오','가지','씨','시키','만들','지금','생각하','그러','속','하나','집','살','모르','적','월','데','자신','안','어떤','내','경우','명','생각','시간','그녀','다시','이런','앞','보이','번','나','다른','어떻','여자','개','전','들','사실','이렇','점','싶','말','정도','좀','원','잘','통하','소리','놓']\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "## Train Data\n",
    "X_train = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(temp_X)\n",
    "    \n",
    "## Test Data\n",
    "X_test = []\n",
    "for sentence in test_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정수 인코딩\n",
    "## Train Data\n",
    "# 단어 집합 생성\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "#print(tokenizer.word_index)\n",
    "\n",
    "\n",
    "## 단어 비중 확인\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "## key, value = 단어와 빈도수의 쌍(pair)\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "#print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "#print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "#print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "#print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "\n",
    "## 등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "#print('단어 집합의 크기 :',vocab_size)\n",
    "\n",
    "\n",
    "## 케라스 토크나이저는 텍스트 시퀀스를 숫자 시퀀스로 변환\n",
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "## Train, Test Data 정답(label)\n",
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 빈 샘플(Empty) 제거\n",
    "# 각 샘플들의 길이를 확인\n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "\n",
    "# 길이=0인 빈 샘플들을 제거\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 동일한 길이로 패딩\n",
    "# 전체 데이터의 길이에 대한 분포 확인\n",
    "#print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "#print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율 확인\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    #print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
    "\n",
    "# 동일한 길이 설정을 위한 전체에 대한 비율 확인\n",
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)\n",
    "\n",
    "# 모두 동일한 길이로 설정(max_len)\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM 모델 설정\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 0.3889 - acc: 0.8241\n",
      "Epoch 00001: val_acc improved from -inf to 0.84279, saving model to best_model.h5\n",
      "1939/1939 [==============================] - 36s 19ms/step - loss: 0.3889 - acc: 0.8241 - val_loss: 0.3521 - val_acc: 0.8428\n",
      "Epoch 2/15\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 0.3271 - acc: 0.8580\n",
      "Epoch 00002: val_acc improved from 0.84279 to 0.85455, saving model to best_model.h5\n",
      "1939/1939 [==============================] - 36s 18ms/step - loss: 0.3270 - acc: 0.8581 - val_loss: 0.3373 - val_acc: 0.8546\n",
      "Epoch 3/15\n",
      "1936/1939 [============================>.] - ETA: 0s - loss: 0.3016 - acc: 0.8719\n",
      "Epoch 00003: val_acc improved from 0.85455 to 0.86102, saving model to best_model.h5\n",
      "1939/1939 [==============================] - 35s 18ms/step - loss: 0.3016 - acc: 0.8719 - val_loss: 0.3257 - val_acc: 0.8610\n",
      "Epoch 4/15\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.8822\n",
      "Epoch 00004: val_acc did not improve from 0.86102\n",
      "1939/1939 [==============================] - 35s 18ms/step - loss: 0.2832 - acc: 0.8822 - val_loss: 0.3306 - val_acc: 0.8572\n",
      "Epoch 5/15\n",
      "1938/1939 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.8900\n",
      "Epoch 00005: val_acc did not improve from 0.86102\n",
      "1939/1939 [==============================] - 35s 18ms/step - loss: 0.2681 - acc: 0.8900 - val_loss: 0.3272 - val_acc: 0.8603\n",
      "Epoch 6/15\n",
      "1936/1939 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.8964\n",
      "Epoch 00006: val_acc did not improve from 0.86102\n",
      "1939/1939 [==============================] - 36s 18ms/step - loss: 0.2547 - acc: 0.8964 - val_loss: 0.3299 - val_acc: 0.8594\n",
      "Epoch 7/15\n",
      "1937/1939 [============================>.] - ETA: 0s - loss: 0.2402 - acc: 0.9030\n",
      "Epoch 00007: val_acc did not improve from 0.86102\n",
      "1939/1939 [==============================] - 35s 18ms/step - loss: 0.2402 - acc: 0.9030 - val_loss: 0.3519 - val_acc: 0.8475\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "### Model 학습 및 생성\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532/1532 [==============================] - 6s 4ms/step - loss: 0.3346 - acc: 0.8531\n",
      "\n",
      " 테스트 정확도: 0.8531\n"
     ]
    }
   ],
   "source": [
    "### 생성된 모델 평가\n",
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    result = 0\n",
    "    if(score > 0.5):\n",
    "        #print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "        result = 1\n",
    "    else:\n",
    "        #print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\n",
    "        result = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-08d71f739e41>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_data['Predicted'][i] = Predicted\n"
     ]
    }
   ],
   "source": [
    "eval_data = pd.read_csv('./[전처리]ko_data.csv', engine='python', encoding='utf-8')\n",
    "eval_data['Predicted'] = 0\n",
    "\n",
    "for i in range(len(eval_data)):\n",
    "    Predicted = sentiment_predict(eval_data['Sentence'][i])\n",
    "    eval_data['Predicted'][i] = Predicted\n",
    "    \n",
    "eval_data.drop(['Sentence'], axis='columns', inplace=True)\n",
    "eval_data.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
