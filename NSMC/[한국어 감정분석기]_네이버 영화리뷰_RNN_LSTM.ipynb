{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN-LSTM 기반의 한국어 감정 분석기\n",
    "##### 네이버 영화 리뷰(NSMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "### 데이터 다운로드 / 로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_table('./ratings_train.txt')\n",
    "test_data = pd.read_table('./ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 데이터 전처리(Train, Test)\n",
    "##### 1) 중복 제거\n",
    "##### 2) Null값 제거\n",
    "##### 3) 한글, 공백 제외 문자 제거\n",
    "##### 4) 전처리 후 Null 값 제거\n",
    "##### 데이터 1차 저장(train_data_set.csv, test_data_set.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data 처리\n",
    "## Train Data 처리\n",
    "\n",
    "# 1. 중복 확인/제거\n",
    "train_data['document'].nunique(), train_data['label'].nunique()\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "\n",
    "# 2. Null값 처리\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "\n",
    "# 3. 전처리(한글과 공백 제외 문자 제거)\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'] = train_data['document'].str.strip()\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# 4. 전처리 후 Null값 처리\n",
    "train_data = train_data.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data 처리\n",
    "## Test Data 에도 동일한 작업 수행\n",
    "\n",
    "# 1.중복 확인/제거\n",
    "test_data['document'].nunique(), test_data['label'].nunique()\n",
    "test_data.drop_duplicates(subset = ['document'], inplace=True)\n",
    "\n",
    "# 2. Null값 처리\n",
    "test_data = test_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "\n",
    "# 3. 전처리(한글과 공백 제외 문자 제거)\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.strip()\n",
    "test_data['document'].replace('', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# 4. 전처리 후 Null값 처리\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 중복, null값, 전처리(한글, 공백 제외), 전처리 후 null값 처리까지 한 데이터 저장\n",
    "# Train Data\n",
    "train_data.to_csv(\"train_data_set.csv\", mode='w', index=False)\n",
    "\n",
    "# Test Data\n",
    "test_data.to_csv(\"test_data_set.csv\", mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 데이터 정제(Train, Test)\n",
    "##### 1) 반복문자 교정\n",
    "##### 2) 띄어쓰기 교정\n",
    "##### 3) 맞춤법 교정\n",
    "##### 데이터 2차 저장(train_last_data.csv, test_last_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리 결과를 저장한 데이터 불러오기\n",
    "train_data = pd.read_csv('./train_data_set.csv')\n",
    "test_data = pd.read_csv('./test_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 정제 설정\n",
    "from soynlp.normalizer import * # 반복문자 교정\n",
    "from pykospacing import spacing # 띄어쓰기 교정\n",
    "from hanspell import spell_checker # 맞춤법 교정           \n",
    "from pandas import Series, DataFrame # 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 정제 수행 : Train Data\n",
    "# 1) 반복문자 교정\n",
    "# 2) 띄어쓰기 교정\n",
    "# 3) 맞춤법 교정\n",
    "# 4) 결과 저장\n",
    "\n",
    "X_train = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = repeat_normalize(sentence, num_repeats=3) # 1) 반복문자 교정\n",
    "    temp_X = spacing(temp_X) # 2) 띄어쓰기 교정\n",
    "    \n",
    "    try:\n",
    "        temp_X = spell_checker.check(temp_X).checked # 3) 맞춤법 교정\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train.append(temp_X)\n",
    "\n",
    "# 4) 저장\n",
    "train_last_data = pd.DataFrame({'id': train_data['id'],\n",
    "                                'document': X_train,\n",
    "                                'label': train_data['label']})\n",
    "\n",
    "train_last_data.to_csv(\"train_last_data.csv\", mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 정제 수행 : Test Data\n",
    "# 1) 반복문자 교정\n",
    "# 2) 띄어쓰기 교정\n",
    "# 3) 맞춤법 교정\n",
    "\n",
    "X_test = []\n",
    "for sentence in test_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = repeat_normalize(sentence, num_repeats=3) # 1) 반복문자 교정\n",
    "    temp_X = spacing(temp_X) # 2) 띄어쓰기 교정\n",
    "    \n",
    "    try:\n",
    "        temp_X = spell_checker.check(temp_X).checked # 3) 맞춤법 교정\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_test.append(temp_X)\n",
    "\n",
    "# 4) 저장\n",
    "test_last_data = pd.DataFrame({'id': test_data['id'],\n",
    "                                'document': X_test,\n",
    "                                'label': test_data['label']})\n",
    "\n",
    "test_last_data.to_csv(\"test_last_data.csv\", mode='w', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 토큰화 및 불용어(Stopword) 제거(Train, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 데이터 불러오기!!\n",
    "\n",
    "train_last_data = pd.read_csv('./train_last_data.csv')\n",
    "test_last_data = pd.read_csv('./test_last_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "okt = Okt()\n",
    "\n",
    "# Stopword(불용어) 설정\n",
    "stopwords = ['은','는','이','가','을','다','를','것','안','만','거','적','한','로','나','점','인','수','내','못','고','왜',\n",
    "             '그','말','때','듯','요','볼','중','좀','아','뭐','네','걸','번','건','줄','년','전','저','기','지','끝','용',\n",
    "             '분','데','난','라','별','알','편','야','두','또','임','여','일','면','속','애','성','엔','서','랑','제','씨',\n",
    "             '냐','함','하','뿐','자','영','시','후','어','몇','눈','신','놈','감','남','준','위','살','간','명','뭔','움',\n",
    "             '봄','삶','영화','에서','이가','이고','이렇다','그렇다','이렇게','그렇게']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data : 토큰화 및 Stopword(불용어) 제거 수행\n",
    "\n",
    "X_train = []\n",
    "for sentence in train_last_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data : 토큰화 및 Stopword(불용어) 제거 수행\n",
    "\n",
    "X_test = []\n",
    "for sentence in test_last_data['document']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 35705\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 18010\n",
      "단어 집합에서 희귀 단어의 비율: 50.44111468981936\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.5392299738327535\n"
     ]
    }
   ],
   "source": [
    "### 정수 인코딩\n",
    "## Train Data\n",
    "# 단어 집합 생성\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "#print(tokenizer.word_index)\n",
    "\n",
    "\n",
    "## 단어 비중 확인\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "## key, value = 단어와 빈도수의 쌍(pair)\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 17697\n"
     ]
    }
   ],
   "source": [
    "## 등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 케라스 토크나이저는 텍스트 시퀀스를 숫자 시퀀스로 변환\n",
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, Test Data 정답(label)\n",
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 빈 샘플(Empty) 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 빈 샘플(Empty) 제거\n",
    "# 각 샘플들의 길이를 확인\n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "\n",
    "# 길이=0인 빈 샘플들을 제거\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 129\n",
      "리뷰의 평균 길이 : 10.217387411585639\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 동일한 길이로 패딩\n",
    "# 전체 데이터의 길이에 대한 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율 확인\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 20 이하인 샘플의 비율: 89.01148095346323\n"
     ]
    }
   ],
   "source": [
    "# 동일한 길이 설정을 위한 전체에 대한 비율 확인\n",
    "max_len = 20\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모두 동일한 길이로 설정(max_len)\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. LSTM 모델 설정 및 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM 모델 설정\n",
    "#from keras.layers import GRU, LSTM, CuDNNGRU, CuDNNLSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('nsmc_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "907/908 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8167\n",
      "Epoch 00001: val_acc improved from -inf to 0.83678, saving model to nsmc_best_model.h5\n",
      "908/908 [==============================] - 23s 25ms/step - loss: 0.4029 - acc: 0.8167 - val_loss: 0.3690 - val_acc: 0.8368\n",
      "Epoch 2/5\n",
      "907/908 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8501\n",
      "Epoch 00002: val_acc improved from 0.83678 to 0.84136, saving model to nsmc_best_model.h5\n",
      "908/908 [==============================] - 23s 26ms/step - loss: 0.3420 - acc: 0.8502 - val_loss: 0.3661 - val_acc: 0.8414\n",
      "Epoch 3/5\n",
      "908/908 [==============================] - ETA: 0s - loss: 0.3156 - acc: 0.8635\n",
      "Epoch 00003: val_acc improved from 0.84136 to 0.84218, saving model to nsmc_best_model.h5\n",
      "908/908 [==============================] - 23s 25ms/step - loss: 0.3156 - acc: 0.8635 - val_loss: 0.3532 - val_acc: 0.8422\n",
      "Epoch 4/5\n",
      "908/908 [==============================] - ETA: 0s - loss: 0.2952 - acc: 0.8750\n",
      "Epoch 00004: val_acc improved from 0.84218 to 0.85062, saving model to nsmc_best_model.h5\n",
      "908/908 [==============================] - 23s 25ms/step - loss: 0.2952 - acc: 0.8750 - val_loss: 0.3452 - val_acc: 0.8506\n",
      "Epoch 5/5\n",
      "907/908 [============================>.] - ETA: 0s - loss: 0.2773 - acc: 0.8858\n",
      "Epoch 00005: val_acc did not improve from 0.85062\n",
      "908/908 [==============================] - 23s 25ms/step - loss: 0.2773 - acc: 0.8858 - val_loss: 0.3542 - val_acc: 0.8478\n"
     ]
    }
   ],
   "source": [
    "### Model 학습 및 생성\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=5, callbacks=[es, mc], batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 0.3507 - acc: 0.8465\n",
      "\n",
      " 테스트 정확도: 0.8465\n"
     ]
    }
   ],
   "source": [
    "### 생성된 모델 평가\n",
    "loaded_model = load_model('nsmc_best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    \n",
    "    new_sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", new_sentence) # 전처리(한글, 공백 제외한 문자 제거)\n",
    "    new_sentence = repeat_normalize(new_sentence, num_repeats=1) # 반복 문자\n",
    "    new_sentence = spacing(new_sentence) # 띄어쓰기\n",
    "    \n",
    "    try:\n",
    "        new_sentence = spell_checker.check(new_sentence).checked # 맞춤법 교정\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    \n",
    "    result = 0  \n",
    "    \n",
    "    if(score > 0.5):\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-225-08d71f739e41>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_data['Predicted'][i] = Predicted\n"
     ]
    }
   ],
   "source": [
    "eval_data = pd.read_csv('./[전처리]ko_data.csv', engine='python', encoding='utf-8')\n",
    "eval_data['Predicted'] = 0\n",
    "\n",
    "for i in range(len(eval_data)):\n",
    "    Predicted = sentiment_predict(eval_data['Sentence'][i])\n",
    "    eval_data['Predicted'][i] = Predicted\n",
    "    \n",
    "eval_data.drop(['Sentence'], axis='columns', inplace=True)\n",
    "eval_data.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
